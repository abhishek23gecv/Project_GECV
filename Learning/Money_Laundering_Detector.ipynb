
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Money Laundering Detection Pipeline\n",
    "This notebook covers:\n",
    "1. Sample dataset creation\n",
    "2. Feature engineering\n",
    "3. Anomaly detection (Isolation Forest)\n",
    "4. Clustering (DBSCAN)\n",
    "5. Transaction graph visualization (NetworkX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sample Data Generation\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "accounts = ['A100', 'B200', 'C300', 'D400']\n",
    "emails = ['a@xyz.com', 'b@xyz.com', 'c@xyz.com', 'd@xyz.com']\n",
    "ips = ['192.168.1.10', '192.168.1.20', '192.168.1.30', '192.168.1.40']\n",
    "phones = ['9999999999', '8888888888', '7777777777', '6666666666']\n",
    "\n",
    "data = []\n",
    "base_time = datetime(2025, 5, 25, 10, 0)\n",
    "\n",
    "for i in range(20):\n",
    "    sender = random.choice(accounts)\n",
    "    receiver = random.choice([a for a in accounts if a != sender])\n",
    "    amount = random.randint(9000, 10000)\n",
    "    time = base_time + timedelta(minutes=i*10)\n",
    "    data.append({\n",
    "        \"txn_id\": i+1,\n",
    "        \"sender_acct\": sender,\n",
    "        \"receiver_acct\": receiver,\n",
    "        \"amount\": amount,\n",
    "        \"timestamp\": time,\n",
    "        \"sender_ip\": ips[accounts.index(sender)],\n",
    "        \"receiver_ip\": ips[accounts.index(receiver)],\n",
    "        \"sender_email\": emails[accounts.index(sender)],\n",
    "        \"receiver_email\": emails[accounts.index(receiver)],\n",
    "        \"sender_phone\": phones[accounts.index(sender)],\n",
    "        \"receiver_phone\": phones[accounts.index(receiver)]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"transactions.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature Engineering\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"transactions.csv\", parse_dates=[\"timestamp\"])\n",
    "df = df.sort_values(\"timestamp\")\n",
    "\n",
    "df[\"time_diff_minutes\"] = df[\"timestamp\"].diff().dt.total_seconds() / 60\n",
    "df[\"amount_diff\"] = df[\"amount\"].diff().fillna(0)\n",
    "df[\"same_ip\"] = (df[\"sender_ip\"] == df[\"receiver_ip\"]).astype(int)\n",
    "df[\"same_phone\"] = (df[\"sender_phone\"] == df[\"receiver_phone\"]).astype(int)\n",
    "\n",
    "def detect_loop(df):\n",
    "    loops = []\n",
    "    sent_from = set()\n",
    "    for idx, row in df.iterrows():\n",
    "        loops.append(1 if row['receiver_acct'] in sent_from else 0)\n",
    "        sent_from.add(row['sender_acct'])\n",
    "    return loops\n",
    "df['is_loop_txn'] = detect_loop(df)\n",
    "\n",
    "df['sender_txn_count'] = df.groupby('sender_acct').cumcount() + 1\n",
    "df['sender_amount_avg'] = df.groupby('sender_acct')['amount'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "df['amount_ratio_prev'] = df['amount'] / (df['amount'].shift(1) + 1e-6)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Anomaly Detection (Isolation Forest)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\n",
    "    \"amount\", \"time_diff_minutes\", \"amount_diff\", \"same_ip\", \"same_phone\",\n",
    "    \"is_loop_txn\", \"sender_txn_count\", \"sender_amount_avg\", \"amount_ratio_prev\"\n",
    "]\n",
    "\n",
    "X = df[features].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "iso = IsolationForest(contamination=0.1, random_state=42)\n",
    "df[\"anomaly_score\"] = iso.fit_predict(X_scaled)\n",
    "df[\"is_anomaly\"] = df[\"anomaly_score\"] == -1\n",
    "\n",
    "df[df[\"is_anomaly\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Clustering (DBSCAN)\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clustering = DBSCAN(eps=1.5, min_samples=3)\n",
    "df[\"cluster\"] = clustering.fit_predict(X_scaled)\n",
    "df[[\"txn_id\", \"sender_acct\", \"receiver_acct\", \"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualization with NetworkX\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    df,\n",
    "    source=\"sender_acct\",\n",
    "    target=\"receiver_acct\",\n",
    "    edge_attr=\"amount\",\n",
    "    create_using=nx.DiGraph()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"skyblue\", node_size=2000, arrowsize=20)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, \"amount\"))\n",
    "plt.title(\"Transaction Flow Graph\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
